<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dev on Le Baron de Charlus</title><link>https://lebaron.sh/tags/dev/</link><description>Recent content in Dev on Le Baron de Charlus</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Le Baron de Charlus</copyright><lastBuildDate>Sun, 30 Jul 2017 15:08:41 +0000</lastBuildDate><atom:link href="https://lebaron.sh/tags/dev/index.xml" rel="self" type="application/rss+xml"/><item><title>Galera Monitoring</title><link>https://lebaron.sh/p/galera-monitoring/</link><pubDate>Sun, 30 Jul 2017 15:08:41 +0000</pubDate><guid>https://lebaron.sh/p/galera-monitoring/</guid><description>&lt;p>Monitoring a database in standalone mode is one thing, but when it comes to clustering, it&amp;rsquo;s a little more complex.&lt;/p>
&lt;p>This is the case with Galera clustering (mariaDB/mysql). Zabbix (&amp;amp;co) offered me simple solutions for single database servers, but I didn&amp;rsquo;t find a really interesting template for monitoring a Galera cluster for production.&lt;/p>
&lt;p>So several questions, what to monitor, how to alert, what&amp;rsquo;s the best method?&lt;/p>
&lt;p>I based myself on &lt;a class="link" href="http://galeracluster.com/documentation-webpages/monitoringthecluster.html" target="_blank" rel="noopener"
>the official Galera documentation&lt;/a> to have all the important elements to monitor.
For the choice of the Golang language, it seemed to me that it provided me with the necessary functionalities.
As for the choice of alerting, I decided to use a Slack App.&lt;/p>
&lt;p>You can find the &lt;a class="link" href="https://github.com/lebarondecharlus/GaleraMonitoring" target="_blank" rel="noopener"
>sources of my project here&lt;/a>.&lt;/p>
&lt;p>Example of a healthy output :&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;gt; go run main.go
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">### Version ####
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Serveur n1 - version 5.6.35-1xenial
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Serveur n2 - version 5.6.35-1xenial
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Serveur n3 - version 5.6.35-1xenial
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">### UUID ###
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n1 a1c404a9-51b4-11e7-b057-237cc5970d38
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n2 a1c404a9-51b4-11e7-b057-237cc5970d38
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n3 a1c404a9-51b4-11e7-b057-237cc5970d38
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">### Nodes ###
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Total Nodes : 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Number of Nodes counts : 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Number of Nodes counts : 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Number of Nodes counts : 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">### STATUS ###
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n1 status : Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n2 status : Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n3 status : Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n1 is ready : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n2 is ready : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n3 is ready : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n1 is connected : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n2 is connected : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 n3 is connected : [ON]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">### Average Replication ###
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Average on n2 : 0.000000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Average on n3 : 0.000000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2017/06/16 14:19:48 Average on n1 : 0.100000
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You have to use the &lt;code>slackApp&lt;/code> package in which I placed an exposed function &lt;code>PayloadSlack()&lt;/code> to then customize your alerts.&lt;/p>
&lt;p>The whole output is not displayed in the &lt;strong>STDOUT&lt;/strong> when it is healthy. Nevertheless you just have to uncomment the println in the &lt;code>main.go&lt;/code> to be able to perform your tests.&lt;/p></description></item><item><title>Event Watcher Manager Python3</title><link>https://lebaron.sh/p/event-watcher-manager-python3/</link><pubDate>Sun, 30 Jul 2017 12:53:16 +0000</pubDate><guid>https://lebaron.sh/p/event-watcher-manager-python3/</guid><description>&lt;p>On one specific request, I had to work on the elaboration of an automating program reacting on SFTP users updates.&lt;br>
The main technical issue of this request is that the SFTP protocol does not have a logging system.&lt;/p>
&lt;p>I had heard about &lt;a class="link" href="https://github.com/seb-m/pyinotify/blob/master/python3/pyinotify.py" target="_blank" rel="noopener"
>the pyinotify library&lt;/a> so I started working on it.&lt;br>
&lt;strong>The project is presented in its primary mechanism&lt;/strong>, for more details, I invite you to read the sources.&lt;/p>
&lt;h4 id="technical-requests-concerning-the-project">Technical requests concerning the project
&lt;/h4>&lt;p>Details of the context of realization :
&lt;/u>Details of the context of realization :&lt;/u>.&lt;br>
The program must monitor SFTP user actions. These users have their HomeDir which are NFS mounts.&lt;br>
The user can upload anything to his account, but the program must detect video uploads (in some formats) and then perform a series of successive actions.&lt;/p>
&lt;p>&amp;lt;The operation should be as follows:&lt;/u>&lt;br>
For each detected video repository, the video must check the allowed format, then it must be converted to .flv, have metadata, have a scree nshot (video thumbnail) and an email must be sent to the SFTP user&amp;rsquo;s email address.&lt;/p>
&lt;h4 id="preparation">Preparation
&lt;/h4>&lt;p>Several specific details are binding to begin with. The main one being the association of the account user&amp;rsquo;s mail to his own mail with the detection of the video repository.&lt;br>
That&amp;rsquo;s why I chose to start on a static file, knowing in advance the list of users.&lt;/p>
&lt;pre>&lt;code># Création de la classe
class Person:
def __init__(self, name, surname, login, homedir, email, realpath):
self.name = name
self.surname = surname
self.login = login
self.homedir = homedir
self.email = email
self.realpath = realpath
#
# Et instanciation des utilisateurs
#
user_test = Person(
'Test',
'test',
'test',
'/test/test/test.fr',
'test@test.fr',
'/test.fr/')
&lt;/code>&lt;/pre>
&lt;p>Then I worked on the &lt;em>core&lt;/em> of the program. First of all to get the information from my user file and to make a grouping by list.&lt;/p>
&lt;pre>&lt;code># Définition des listes
user_list = []
user_path = []
user_mail = []
user_realpath = []
# On appelle le fichier utilisateur pour implémenter les listes
### LOGIN ###
for users.obj in gc.get_objects():
if isinstance(users.obj, users.Person):
user_list.append(users.obj.login)
### DOCUMENT_ROOT ###
for users.obj in gc.get_objects():
if isinstance(users.obj, users.Person):
user_path.append(users.obj.homedir
### EMAIL ###
for users.obj in gc.get_objects():
if isinstance(users.obj, users.Person):
user_mail.append(users.obj.email)
### REALPATH ###
for users.obj in gc.get_objects():
if isinstance(users.obj, users.Person):
user_realpath.append(users.obj.realpath)
&lt;/code>&lt;/pre>
&lt;p>The definition of a first function whose purpose will be the associative call with an ID position system.&lt;/p>
&lt;pre>&lt;code>def owner_func():
for filename in multiple_file_types('*.avi', '*.mov', '*.mp4', '*.mpg', '*.wmv'):
# On affiche l'utilisateur
owner = pwd.getpwuid(os.stat(filename).st_uid).pw_name
# On vérifie que ce dernier est bien présent dans notr liste
if owner in user_list:
print('The owner of file is : ' + owner)
position = user_list.index(owner)
print('Owner_login_path :' + user_path[position])
mail = user_mail[position]
mailp = print(mail)
realpath = user_realpath[position]
return(realpath)
else:
print('The owner was not found.')
&lt;/code>&lt;/pre>
&lt;h4 id="pyinotifier-introduction">Pyinotifier Introduction
&lt;/h4>&lt;p>Pyinotifier has functions related to the creation and deletion of data (IN_CREATE and IN_DELETE).&lt;br>
Once the basic setup was done, I used the basic definition to implement with the &lt;strong>owner_func()&lt;/strong> function.&lt;/p>
&lt;pre>&lt;code>class EventHandler(pyinotify.ProcessEvent):
def process_IN_CREATE(self, event):
print('\n\n===========================')
print(time.strftime(&amp;quot;%d/%m/%Y %H:%M:%S&amp;quot;))
evp = print('Path complet :' + '\'' + event.pathname + '\'')
evn = print('Objet crée : ' + '\'' + event.name + '\'')
Ouser = event.pathname.split('/')[2]
print('Utilisateur : ' + Ouser)
Oplace = [i for i,x in enumerate(user_list) if x == Ouser][0]
Orelatif = user_realpath[Oplace]
Omail = user_mail[Oplace]
print('Chroot Sftp : ' + Orelatif)
print('Mail : ' + Omail)
command = 'convert.bash '+str(event.pathname)
previous_size=0
upload_finished = False
try:
while True:
time.sleep(1)
size=os.stat(event.pathname).st_size
print(previous_size)
print(size)
if size == previous_size:
break
else:
previous_size = size
except:
return False
print(command)
os.rename(event.pathname, event.pathname.replace(&amp;quot; &amp;quot;, &amp;quot;_&amp;quot;))
neventpathname = event.pathname.replace(' ', '_')
neventname = event.name.replace(' ', '_')
print(neventpathname + neventname)
p1 = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
print('convert.bash', neventpathname)
print(p1.stdout.read())
p1.wait()
p2 = subprocess.Popen(['generatemetadata.bash', neventpathname])
p2.wait()
p3 = subprocess.Popen(['extractpng.sh', neventpathname])
p3.wait()
if neventname.endswith('.html') :
p5 = subprocess.Popen(['mail.bash', Omail, Orelatif, neventpathname])
print('MAIL SENT')
print('===========================')
def process_IN_DELETE(self, event):
print('\n\n===========================')
print(time.strftime(&amp;quot;%d/%m/%Y %H:%M:%S&amp;quot;) + &amp;quot; Deleting:&amp;quot;, event.pathname)
print('===========================')
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Explanations :&lt;/strong>&lt;br>
The principle of Pyinotify is to create an automatic action at a given event. Let&amp;rsquo;s take the deposit of a video corresponding to the right format as the event.&lt;br>
The &lt;strong>IN_CREATE&lt;/strong> function is then triggered and will send us first information including: the creation date, the full path of the event, the relative path (HomeDir of the SFTP user), the user, his email&amp;hellip;&lt;/p>
&lt;p>In a second step we apply the conversion to the right format (with &lt;strong>ffmpeg&lt;/strong>). However, we have to make sure that the video is complete and submitted. This corresponds to the block :&lt;/p>
&lt;pre>&lt;code> command = 'convert.bash '+str(event.pathname)
previous_size=0
upload_finished = False
try:
while True:
time.sleep(1)
size=os.stat(event.pathname).st_size
print(previous_size)
print(size)
if size == previous_size:
break
else:
previous_size = size
except:
return False
print(command)
&lt;/code>&lt;/pre>
&lt;p>Then we will be able to run the bash scripts in subprocess.&lt;/p>
&lt;h4 id="interests">Interests
&lt;/h4>&lt;p>The interests are multiple!&lt;br>
The first one is obvious since it is now possible to perform a logging on a service that was not natively available. The second one is that it is possible to set up a logging and PID system very simply.&lt;/p>
&lt;pre>&lt;code>notifier.loop(daemonize=True, callback=on_loop_func, pid_file='logs/pyinotify.pid', stdout='logs/%s.log' % timestr)
&lt;/code>&lt;/pre>
&lt;p>This opens a very interesting new door on event automation by a Python subroutine that would take the work done by the kernel out of the box.&lt;/p>
&lt;p>I was just thinking of making a kind of API calling this type of operation scalable on different environments.&lt;br>
This project being in my famous &lt;strong>ToDoList&lt;/strong> would be very close to a Master-Slaving system with certainly an imitation of what already exists with Puppet &amp;hellip; but in Python.&lt;/p>
&lt;p>Wait and see what will be done !&lt;/p></description></item></channel></rss>